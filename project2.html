<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Speech Evaluation System</title>
  <style>
    body {
      margin: 0;
      font-family: 'Roboto', sans-serif;
      background-color: #f7f7f7;
    }

    /* Navbar styles */
   .navbar {
      background-color: black;
      overflow: hidden;
      text-align: center;
    }

    .navbar a {
      display: inline-block;
      color: #dbdbdb;
      padding: 14px 20px;
      text-decoration: none;
      font-size: 17px;
    }

    .navbar a:nth-child(1),
    .navbar a:nth-child(2) {
      margin: 0 10px;
    }

    .navbar a:hover {
      color: #a6a6a6;
    }


    /* Project Section */
    .project-section {
      padding: 20px;
      max-width: 900px;
      margin: 40px auto;
      background-color: white;
      border-radius: 8px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }

    .project-header {
      font-size: 28px;
      font-weight: bold;
      margin-bottom: 20px;
      text-align: center;
    }

    /* YouTube video embed */
    .video-container {
      text-align: center;
      margin-bottom: 30px;
    }

    .video-container iframe {
      border: none;
      border-radius: 8px;
      max-width: 100%;
    }

    /* Common section styles */
    .section {
      margin: 20px 0;
    }

    h4 {
      font-size: 20px;
      margin-bottom: 10px;
      color: #333;
    }

    p {
      line-height: 1.6;
      font-size: 16px;
      color: #555;
    }

    /* Contributions listing */
    .contributions {
      margin-top: 30px;
    }

    /* List style for skills & technologies */
    ul {
      list-style-type: disc;
      margin: 10px 0 20px 20px;
    }

    li {
      font-size: 16px;
      margin: 8px 0;
      color: #444;
    }

    /* Footer */
    footer {
      text-align: center;
      padding: 20px 0;
      font-size: 14px;
      color: #888;
      background-color: #333;
      color: white;
    }
  </style>
</head>

<body>

  <!-- Navigation Bar -->
  <div class="navbar">
    <a href="index.html">Home</a>
    <a href="project.html">Projects</a>
  </div>

  <!-- Project Section -->
  <div class="project-section">
    <div class="project-header">AI Speech Evaluation System</div>

    <!-- YouTube Video Embed -->
    <div class="video-container">
      <iframe width="560" height="315" src="https://www.youtube.com/embed/fNiZ1P9HDeA" allowfullscreen></iframe>
    </div>

    <!-- Contributions Listing -->
    <div class="section contributions">
      <h4>Contributions</h4>
      <p>This is an individual project created for MongoDB AI Hackathon: Code for a Cause. <a href="#">[GitHub]</a></p>
    </div>

    <!-- Skills & Technologies -->
    <div class="section skills">
      <h4>Skills & Technologies Used</h4>
      <ul>
        <li>MongoDB Atlas</li>
        <li>Gemini</li>
        <li>React</li>
        <li>Node.js</li>
        <li>AWS hosting</li>
      </ul>
    </div>

    <!-- Inspiration Section -->
    <div class="section inspiration">
        <h4>Inspiration</h4>
        <p>In today's competitive world, effective communication is one of the most crucial skills for leadership and career growth. Yet many women face barriers in expressing their ideas confidently, clearly, and with the structure needed to influence decision-making and leadership dynamics. To address this, we built an AI-powered real-time speech analysis tool that provides actionable insights to improve clarity, structure, and confidence in communication. This tool empowers users by giving detailed feedback, helping them grow their leadership presence and career potential. By delivering personalised, data-driven guidance, the tool aims to provide support to overcome communication challenges and thrive in leadership roles.</p>
    </div>

    <!-- What it does Section -->
    <div class="section what-it-does">
        <h4>What it does</h4>
        <p>The tool provides users with the ability to refine their communication skills through a dynamic, interactive experience. Here's how it works:</p>
        <ul>
            <li><strong>Start Recording:</strong> The user begins by recording their speech on any topic. This can be for a presentation, a meeting rehearsal, or simply practicing everyday conversations.</li>
            <li><strong>Instant Feedback on Filler Words:</strong> While speaking, the tool monitors for the use of filler words (such as "um," "uh," "like," and "you know"). Whenever filler words are detected repeatedly, the speaker icon changes from green to red, giving an immediate visual cue that the user is relying on fillers too often.</li>
            <li><strong>Recording Completed:</strong> Once the user finishes speaking, the full speech recording is sent to Gemini for an in-depth analysis of several key aspects.</li>
        </ul>
    </div>

    <!-- How We Built It Section -->
    <div class="section how-we-built">
        <h4>How we built it</h4>
        <p><strong>Frontend (HTML and CSS):</strong> The user interface is built with HTML and CSS, designed to be simple and responsive. The main elements include a Start Recording button, a Speaker Icon (which changes color based on filler word detection). The frontend captures audio from the userâ€™s microphone and sends it to the backend in real-time.</p>

        <p><strong>Backend (Node.js Server):</strong> Node.js manages the incoming audio data from the frontend and facilitates communication between the different services. When the user starts recording, audio data is processed and broken down into small segments that can be analysed for filler words.</p>

        <p><strong>Real-time Analysis:</strong> As the audio segments are received, they are checked against a database of filler word embeddings (stored in MongoDB Atlas). Each incoming audio segment is converted into a vector (embedding) and matched in real-time through a vector search. If filler words are detected frequently, the server sends a signal to the frontend to change the speaker icon from green to red.</p>

        <p><strong>MongoDB Atlas (Database):</strong> MongoDB Atlas is used to store embeddings of common filler words. This allows for fast vector-based searches, helping to identify when the user is using filler words in real-time. Each filler word audio segment is preprocessed and stored as a vector in the database for efficient retrieval and matching.</p>

        <p><strong>Gemini Analysis (Flask API):</strong> After the user completes their recording, the full audio is sent to Gemini, which is connected through a Flask API. Gemini performs a deeper analysis on:</p>
        <ul>
            <li><strong>Sentence Structure and Grammar:</strong> It evaluates sentence flow and highlights grammar issues.</li>
            <li><strong>Speech Clarity and Pace:</strong> It assesses pronunciation clarity and speed.</li>
            <li><strong>Pitch and Confidence:</strong> It analyzes vocal pitch and tone variation to estimate the confidence level of the speaker.</li>
        </ul>
        <p>Once Gemini completes the analysis, it returns a score and detailed feedback.</p>
    </div>

    <!-- Results Section -->
    <div class="section results">
        <h4>Results & Future Scope</h4>
        <p>The tool helps users improve their communication skills with real-time and post-speech feedback. The future scope includes adding multilingual support, emotion and sentiment analysis, integration with video conferencing platforms, and adaptive learning for more personalized feedback. These enhancements aim to make the tool more inclusive and impactful across diverse professional and personal scenarios.</p>
    </div>
  </div>

</body>

</html>
